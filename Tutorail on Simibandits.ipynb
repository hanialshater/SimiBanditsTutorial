{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Software developers are eager to expand there arsinal of algorithms, from shortest path to complex constrain optimization.\n",
    "what if you can use you favorite algorithm even though you don't know the problem parameters, for example to solve shortest path\n",
    "without knowing the edge weights or solving linear programs without knowing the ?? matrix. Seems amazing, isn't it?\n",
    "\n",
    "\n",
    "Actually, there is a set of algorithms that exactly do that, if you ask yourself why these are not popular, there are few reasons. first, the papers on the topic are very theoratical and include pages of pages of proofs, moreover, the research is focusing on finding bounds of how well these algorithms works under cenrain asumptions and when they come to the real world dataset, they provide far from optimal solution and comment \"not bad give our unrealistic asumptions !\". When I started reading first paper on the topic, it took me few days to decrypit the math, convex analysis, banach spaces, martignles and other brain eating beasts. In this series I will try to save more brain cells and present algorithm in the money making sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "### What is on our plat\n",
    "I will assume no prior kowladge in machine learing, this serise will be self contained, all the algorithms presented are implemented in python. So we have seven parts, the first part will explain some important concepts in machine learing and present two simple learning algorithms\n",
    "...\n",
    "\n",
    "links\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "### Part 1: Concepts from machine learning\n",
    "#### ML and why it works\n",
    "Machine learning is a set of methods and algorithms that give the machine ability to learn without being explicitly prgrammed, for example instead of programming a dron to fly, it can learn to fly with eather by imatating another flyting dron or by experimenting itself. Machine learing a mature field with many defintions, directions an applications. Here I will present some concepts that will help you understanding next posts.\n",
    "\n",
    "Simple example, lets say you are observing some seller trying to sell a product to customers, for 5 customers you got the following results [Succeed, Fail, Succeed, Succeed, Fail], what is the probability that the agent. It is simple $\\frac{\\#Success}{\\#Success + \\#Fail} = 0.6$. \n",
    "\n",
    "Congrats you just discoverd your first machine learning algorithm. So why does this work? There is some inequalities from probability theory that tell us that, these are called concentration inequalities and provide bounds on how a random variable deviates from some value. For example, one ineqaulity called Chebyshev's inequality states that $P(\\left|X - E(X)\\right| >= \\alpha) <= \\frac{Var(X)}{\\alpha^2}$, we will use this show that average can't be far from the ture mean! If you don't like math just skip it, we are trying to save your brain cells, remember?!\n",
    "\n",
    "Proof,\n",
    "Recall that $Var(aX + bY) = a^2Var(X) + b^2Var(Y)$, now $Var(\\overline{X}) = Var(\\frac{X_1 + X_2 + .. + X_n}{n}) = \\frac{nVar(X)}{n^2} = \\frac{Var(X)}{n}$ plug into Chebyshev's inequality you have \n",
    "    $$P(\\left|X - E(X)\\right| >= \\alpha) <= \\frac{Var(X)}{n\\alpha^2}$$\n",
    "This means as n grows the probability of having sample average far from the population mean is going to zero. \n",
    "\n",
    "This kind of analysis is used over and over to prove that algorithms are optimal. indeed, there are stronger results that put tighter bounds on the error, however in favour of simplicity we will not go into them here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual vs feature case\n",
    "When you want to learn about some entity, like student expected scores at exame, you have two ways: first method is to put the student to the exame multiple times and estimate his performance, this case is called the individual case. Second, you may observe multiple students and infer a rule like sudents who have better IQ and study for resonable ammount of time will have higher scores, this case is called the feature case. In the feature case, you represent the student with set of features like (study time, IQ, attendence, etc.) and based on these make your judgment. The features allow the algorithm to scale to any number of students.In machine learing termenology, students are called examples and scores are called predictions.\n",
    "\n",
    "There are two popular models for the feature case, linear regression and logstic regression. In linear regression the predictions y = $N(\\theta X, \\sigma)$ \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Example of linear regression (Boston)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Example of logistic regression ()\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Maximum likelyhood estimator (MLE)\n",
    "E.g. MLE of ber, gaussian\n",
    "\n",
    "individual ber -> logistic\n",
    "           gaussian -> linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Digression on stocastic optimization\n",
    "loss and mle, optmizing the loss,\n",
    "Sad poof of exact optimization => numerical algorithms SGD !\n",
    "\n",
    "logistic regression example \n",
    "\n",
    "Ber seems simple, building block for more complex models \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The story so far \n",
    "* Bound on average \n",
    "* Individual vs feature case \n",
    "* MLE \n",
    "    * Bernulli\n",
    "    * Normal\n",
    "    * Linear regression\n",
    "    * logistic regression\n",
    "* In more complex models use loss instead\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# code for ber and normal MLE\n",
    "class GaussianMle:\n",
    "    def __call__(self, array):\n",
    "        return np.mean(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAP, bayesian inference\n",
    "MLE , MAP (A fork in the middel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# code of beta-bernulli\n",
    "class BernoulliLearner:\n",
    "    def __init__(self, alpha0, beta0):\n",
    "        self.params = (alpha0, beta0)\n",
    "    \n",
    "    def update_batch(self, x):\n",
    "        xp = np.sum(x==1)\n",
    "        xn = np.sum(x==0)\n",
    "        alpha0, beta0 = self.params\n",
    "        #set_trace()\n",
    "        self.params = (alpha0 + xp, beta0 + xn)\n",
    "        \n",
    "    def sample(self):\n",
    "        alpha, beta = self.params\n",
    "        theta_sample = np.random.beta(alpha, beta) \n",
    "        return np.random.binomial(1, theta_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# code of Normal-Gamma\n",
    "#https://people.eecs.berkeley.edu/~jordan/courses/260-spring10/lectures/lecture5.pdf\n",
    "\n",
    "class GaussianLearner:\n",
    "    def __init__(self, mu0, n0, tau0, alpha0, beta0):\n",
    "        self.mu_params = (float(mu0), float(n0), float(tau0))\n",
    "        self.tau_params = (float(alpha0), float(beta0))\n",
    "    \n",
    "    def update_batch(self, x):\n",
    "        alpha0, beta0 = self.tau_params\n",
    "        mu0, n0, tau0 = self.mu_params\n",
    "        n = len(x)\n",
    "        xbar = np.mean(x)\n",
    "        \n",
    "        self.tau_params = (alpha0 + n / 2.0,\n",
    "                          beta0 + 0.5 * (np.sum((x - xbar) ** 2)))# + (n * n0) / (2 * (n + n0)) * (xbar - mu0) ** 2))\n",
    "        \n",
    "        t1 = 1 / (n + n0)\n",
    "        self.mu_params = (n * t1 * xbar + n0 * t1 * mu0, n + n0, self.tau_params[0]/self.tau_params[1])\n",
    "        \n",
    "    def sample(self):\n",
    "        alpha, beta = self.tau_params\n",
    "        mu, n, tau = self.mu_params\n",
    "        mu_sample = np.random.normal(mu, np.sqrt(1. / n*tau))\n",
    "        tau_sample = np.random.gamma(alpha, beta) \n",
    "        return np.random.normal(mu_sample, np.sqrt(1. / tau_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Digress on more complex models NN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# code of simple feedforward network\n",
    "# bayes by back prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summery and take a ways \n",
    "* Summery\n",
    "* ML and why it work \n",
    "* Individaul vs feature case \n",
    "* MLE, MAP, Loss \n",
    "* Ber -> logistic\n",
    "* Normal -> Linear\n",
    "* NN\n",
    "\n",
    "Algorithms:\n",
    "1. MLE for ber\n",
    "2. MLE for normal\n",
    "3. Simple logistic\n",
    "4. Simple linear\n",
    "5. Beta-Bernulli\n",
    "6. Normal-GammaNormal\n",
    "7. Bayesian regression\n",
    "8. FFNN\n",
    "9. Bayes by back prob\n",
    "\n",
    "Armed with this knowladge we can go to grap some bandits! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Bandits (Learn about only what matters)\n",
    "* UCB1\n",
    "* Thombson sampling\n",
    "* Code & examples of ber and gaussian\n",
    "* Comparison \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you have 5 works working on writing articles task, you want to pic the most skilled one and allocate others to other projecst, what will you do?!\n",
    "\n",
    "The trivial solution is to make each worker answering customer phane calles, find the average return for each of them, bound that with some confidence interval or error bound, then pic the best. This is fine, however it is too much waistful. Lets say there returns per task are [4, 25, 30, 2, 5], you don't want to make worker with return 2 answer 10 phane calles to realize he is not fit to the job, so we need to learn more about high performant workers and learn less about less perofrmant workers. This problem is called multiarmed bandit.\n",
    "\n",
    "So, formally multi arm bandits MAB is a ...\n",
    "define regret\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Greedy & $\\epsilon$-greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# code for epsilon greedy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizm in face of uncertinity UCB1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# code for UCB1 (Ber and gaussian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thumboson sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code for thumbson sampling \n",
    "class Bandit:\n",
    "    def __init__(self, arm_class, arm_init_params, n_arms):\n",
    "        self.arms = [arm_class(*arm_init_params) for arm in range(n_arms)]\n",
    "    \n",
    "    def thompson_sample(self):\n",
    "        samples = np.array([self.arms[i].sample() for i in range(len(self.arms))])\n",
    "        sample = np.random.choice(np.where(samples[np.argmax(samples)] == samples)[0], 1)[0]\n",
    "        return (sample, samples[sample])\n",
    "    \n",
    "    def sumbit_feedback(self, arm, result_array):\n",
    "        self.arms[arm].update_batch(result_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UBC vs thumbson sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Bandits (The feature case)\n",
    "* linucb and application for top-k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
