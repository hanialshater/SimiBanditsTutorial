{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from striatum.storage import history\n",
    "from striatum.storage import model\n",
    "from striatum.bandit import ucb1\n",
    "from striatum.bandit import linucb\n",
    "from striatum.bandit import linthompsamp\n",
    "from striatum.bandit import exp4p\n",
    "from striatum.bandit import exp3\n",
    "from striatum.storage import Action\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "\n",
    "def movie_preprocessing(movie):\n",
    "    movie_col = list(movie.columns)\n",
    "    movie_tag = [doc.split('|') for doc in movie['tag']]\n",
    "    tag_table = {token: idx for idx, token in enumerate(set(itertools.chain.from_iterable(movie_tag)))}\n",
    "    movie_tag = pd.DataFrame(movie_tag)\n",
    "    tag_table = pd.DataFrame(tag_table.items())\n",
    "    tag_table.columns = ['Tag', 'Index']\n",
    "\n",
    "    # use one-hot encoding for movie genres (here called tag)\n",
    "    tag_dummy = np.zeros([len(movie), len(tag_table)])\n",
    "\n",
    "    for i in range(len(movie)):\n",
    "        for j in range(len(tag_table)):\n",
    "            if tag_table['Tag'][j] in list(movie_tag.iloc[i, :]):\n",
    "                tag_dummy[i, j] = 1\n",
    "\n",
    "    # combine the tag_dummy one-hot encoding table to original movie files\n",
    "    movie = pd.concat([movie, pd.DataFrame(tag_dummy)], 1)\n",
    "    movie_col.extend(['tag' + str(i) for i in range(len(tag_table))])\n",
    "    movie.columns = movie_col\n",
    "    movie = movie.drop('tag', 1)\n",
    "    return movie\n",
    "\n",
    "\n",
    "def feature_extraction(data):\n",
    "    # actions: we use top 50 movies as our actions for recommendations\n",
    "    actions = data.groupby('movie_id').size().sort_values(ascending=False)[:50]\n",
    "    actions = list(actions.index)\n",
    "\n",
    "    # user_feature: tags they've watched for non-top-50 movies normalized per user\n",
    "    user_feature = data[~data['movie_id'].isin(actions)]\n",
    "    user_feature = user_feature.groupby('user_id').aggregate(np.sum)\n",
    "    user_feature = user_feature.drop(['movie_id', 'rating', 'timestamp'], 1)\n",
    "    user_feature = user_feature.div(user_feature.sum(axis=1), axis=0)\n",
    "\n",
    "    # streaming_batch: the result for testing bandit algrorithms\n",
    "    top50_data = data[data['movie_id'].isin(actions)]\n",
    "    top50_data = top50_data.sort_values(by=['timestamp'], ascending=1)\n",
    "    streaming_batch = top50_data['user_id']\n",
    "\n",
    "    # reward_list: if rating >=3, the user will watch the movie\n",
    "    top50_data['reward'] = np.where(top50_data['rating'] >= 3, 1, 0)\n",
    "    reward_list = top50_data[['user_id', 'movie_id', 'reward']]\n",
    "    reward_list = reward_list[reward_list['reward'] == 1]\n",
    "    return streaming_batch, user_feature, actions, reward_list\n",
    "\n",
    "\n",
    "def main():\n",
    "    # read and preprocess the movie data\n",
    "    movie = pd.read_table('ml-1m/movies.dat', sep='::', names=['movie_id', 'movie_name', 'tag'], engine='python')\n",
    "    movie = movie_preprocessing(movie)\n",
    "\n",
    "    # read the ratings data and merge it with movie data\n",
    "    rating = pd.read_table(\"ml-1m/ratings.dat\", sep=\"::\",\n",
    "                           names=[\"user_id\", \"movie_id\", \"rating\", \"timestamp\"], engine='python')\n",
    "    data = pd.merge(rating, movie, on=\"movie_id\")\n",
    "\n",
    "    # extract feature from our data set\n",
    "    streaming_batch, user_feature, actions, reward_list = feature_extraction(data)\n",
    "    streaming_batch.to_csv(\"streaming_batch.csv\", sep='\\t', index=False)\n",
    "    user_feature.to_csv(\"user_feature.csv\", sep='\\t')\n",
    "    pd.DataFrame(actions, columns=['movie_id']).to_csv(\"actions.csv\", sep='\\t', index=False)\n",
    "    reward_list.to_csv(\"reward_list.csv\", sep='\\t', index=False)\n",
    "\n",
    "    action_context = movie[movie['movie_id'].isin(actions)]\n",
    "    action_context.to_csv(\"action_context.csv\", sep='\\t', index = False)\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    streaming_batch = pd.read_csv('streaming_batch.csv', sep='\\t', names=['user_id'], engine='c')\n",
    "    user_feature = pd.read_csv('user_feature.csv', sep='\\t', header=0, index_col=0, engine='c')\n",
    "    actions_id = list(pd.read_csv('actions.csv', sep='\\t', header=0, engine='c')['movie_id'])\n",
    "    reward_list = pd.read_csv('reward_list.csv', sep='\\t', header=0, engine='c')\n",
    "    action_context = pd.read_csv('action_context.csv', sep='\\t', header=0, engine='c')\n",
    "\n",
    "    actions = []\n",
    "    for key in actions_id:\n",
    "        action = Action(key)\n",
    "        actions.append(action)\n",
    "    return streaming_batch, user_feature, actions, reward_list, action_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_batch, user_feature, actions, reward_list, action_context = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    streaming_batch = pd.read_csv('streaming_batch.csv', sep='\\t', names=['user_id'], engine='c')\n",
    "    user_feature = pd.read_csv('user_feature.csv', sep='\\t', header=0, index_col=0, engine='c')\n",
    "    actions_id = list(pd.read_csv('actions.csv', sep='\\t', header=0, engine='c')['movie_id'])\n",
    "    reward_list = pd.read_csv('reward_list.csv', sep='\\t', header=0, engine='c')\n",
    "    action_context = pd.read_csv('action_context.csv', sep='\\t', header=0, engine='c')\n",
    "\n",
    "    actions = []\n",
    "    for key in actions_id:\n",
    "        action = Action(key)\n",
    "        actions.append(action)\n",
    "    return streaming_batch, user_feature, actions, reward_list, action_context\n",
    "\n",
    "\n",
    "def train_expert(action_context):\n",
    "    logreg = OneVsRestClassifier(LogisticRegression())\n",
    "    mnb = OneVsRestClassifier(MultinomialNB(), )\n",
    "    logreg.fit(action_context.iloc[:, 2:], action_context.iloc[:, 1])\n",
    "    mnb.fit(action_context.iloc[:, 2:], action_context.iloc[:, 1])\n",
    "    return [logreg, mnb]\n",
    "\n",
    "\n",
    "def get_advice(context, actions_id, experts):\n",
    "    advice = {}\n",
    "    for time in context.keys():\n",
    "        advice[time] = {}\n",
    "        for i in range(len(experts)):\n",
    "            prob = experts[i].predict_proba(context[time])[0]\n",
    "            advice[time][i] = {}\n",
    "            for j in range(len(prob)):\n",
    "                advice[time][i][actions_id[j]] = prob[j]\n",
    "    return advice\n",
    "\n",
    "\n",
    "def policy_generation(bandit, actions):\n",
    "    historystorage = history.MemoryHistoryStorage()\n",
    "    modelstorage = model.MemoryModelStorage()\n",
    "\n",
    "    if bandit == 'Exp4P':\n",
    "        policy = exp4p.Exp4P(actions, historystorage, modelstorage, delta=0.5, pmin=None)\n",
    "\n",
    "    elif bandit == 'LinUCB':\n",
    "        policy = linucb.LinUCB(actions, historystorage, modelstorage, 0.3, 20)\n",
    "\n",
    "    elif bandit == 'LinThompSamp':\n",
    "        policy = linthompsamp.LinThompSamp(actions, historystorage, modelstorage,\n",
    "                                           d=20, delta=0.61, r=0.01, epsilon=0.71)\n",
    "\n",
    "    elif bandit == 'UCB1':\n",
    "        policy = ucb1.UCB1(actions, historystorage, modelstorage)\n",
    "\n",
    "    elif bandit == 'Exp3':\n",
    "        policy = exp3.Exp3(actions, historystorage, modelstorage, gamma=0.2)\n",
    "\n",
    "    elif bandit == 'random':\n",
    "        policy = 0\n",
    "\n",
    "    return policy\n",
    "\n",
    "\n",
    "def policy_evaluation(policy, bandit, streaming_batch, user_feature, reward_list, actions, action_context=None):\n",
    "    times = len(streaming_batch)\n",
    "    seq_error = np.zeros(shape=(times, 1))\n",
    "    actions_id = [actions[i].action_id for i in range(len(actions))]\n",
    "    if bandit in ['LinUCB', 'LinThompSamp', 'UCB1', 'Exp3']:\n",
    "        for t in range(times):\n",
    "            feature = np.array(user_feature[user_feature.index == streaming_batch.iloc[t, 0]])[0]\n",
    "            full_context = {}\n",
    "            for action_id in actions_id:\n",
    "                full_context[action_id] = feature\n",
    "            history_id, action = policy.get_action(full_context, 1)\n",
    "            watched_list = reward_list[reward_list['user_id'] == streaming_batch.iloc[t, 0]]\n",
    "\n",
    "            if action[0]['action'].action_id not in list(watched_list['movie_id']):\n",
    "                policy.reward(history_id, {action[0]['action'].action_id: 0.0})\n",
    "                if t == 0:\n",
    "                    seq_error[t] = 1.0\n",
    "                else:\n",
    "                    seq_error[t] = seq_error[t - 1] + 1.0\n",
    "\n",
    "            else:\n",
    "                policy.reward(history_id, {action[0]['action'].action_id: 1.0})\n",
    "                if t > 0:\n",
    "                    seq_error[t] = seq_error[t - 1]\n",
    "\n",
    "    elif bandit == 'Exp4P':\n",
    "        for t in range(times):\n",
    "            feature = user_feature[user_feature.index == streaming_batch.iloc[t, 0]]\n",
    "            experts = train_expert(action_context)\n",
    "            advice = {}\n",
    "            for i in range(len(experts)):\n",
    "                prob = experts[i].predict_proba(feature)[0]\n",
    "                advice[i] = {}\n",
    "                for j in range(len(prob)):\n",
    "                    advice[i][actions_id[j]] = prob[j]\n",
    "            history_id, action = policy.get_action(advice)\n",
    "            watched_list = reward_list[reward_list['user_id'] == streaming_batch.iloc[t, 0]]\n",
    "\n",
    "            if action[0]['action'].action_id not in list(watched_list['movie_id']):\n",
    "                policy.reward(history_id, {action[0]['action'].action_id: 0.0})\n",
    "                if t == 0:\n",
    "                    seq_error[t] = 1.0\n",
    "                else:\n",
    "                    seq_error[t] = seq_error[t - 1] + 1.0\n",
    "\n",
    "            else:\n",
    "                policy.reward(history_id, {action[0]['action'].action_id: 1.0})\n",
    "                if t > 0:\n",
    "                    seq_error[t] = seq_error[t - 1]\n",
    "\n",
    "    elif bandit == 'random':\n",
    "        for t in range(times):\n",
    "            action = actions_id[np.random.randint(0, len(actions)-1)]\n",
    "            watched_list = reward_list[reward_list['user_id'] == streaming_batch.iloc[t, 0]]\n",
    "\n",
    "            if action not in list(watched_list['movie_id']):\n",
    "                if t == 0:\n",
    "                    seq_error[t] = 1.0\n",
    "                else:\n",
    "                    seq_error[t] = seq_error[t - 1] + 1.0\n",
    "\n",
    "            else:\n",
    "                if t > 0:\n",
    "                    seq_error[t] = seq_error[t - 1]\n",
    "\n",
    "    return seq_error\n",
    "\n",
    "\n",
    "def regret_calculation(seq_error):\n",
    "    t = len(seq_error)\n",
    "    regret = [x / y for x, y in zip(seq_error, range(1, t + 1))]\n",
    "    return regret\n",
    "\n",
    "\n",
    "def main():\n",
    "    streaming_batch, user_feature, actions, reward_list, action_context = get_data()\n",
    "    streaming_batch_small = streaming_batch.iloc[0:10000]\n",
    "\n",
    "    # conduct regret analyses\n",
    "    experiment_bandit = ['LinUCB', 'LinThompSamp', 'Exp4P', 'UCB1', 'Exp3', 'random']\n",
    "    regret = {}\n",
    "    col = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'w']\n",
    "    i = 0\n",
    "    for bandit in experiment_bandit:\n",
    "        policy = policy_generation(bandit, actions)\n",
    "        seq_error = policy_evaluation(policy, bandit, streaming_batch_small, user_feature, reward_list,\n",
    "                                      actions, action_context)\n",
    "        regret[bandit] = regret_calculation(seq_error)\n",
    "        plt.plot(range(len(streaming_batch_small)), regret[bandit], c=col[i], ls='-', label=bandit)\n",
    "        plt.xlabel('time')\n",
    "        plt.ylabel('regret')\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "        axes = plt.gca()\n",
    "        axes.set_ylim([0, 1])\n",
    "        plt.title(\"Regret Bound with respect to T\")\n",
    "        i += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MemoryModelStorage' object has no attribute 'iterids'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-58ca95c5b364>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-cdd57662563b>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbandit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiment_bandit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbandit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         seq_error = policy_evaluation(policy, bandit, streaming_batch_small, user_feature, reward_list,\n\u001b[1;32m    147\u001b[0m                                       actions, action_context)\n",
      "\u001b[0;32m<ipython-input-22-cdd57662563b>\u001b[0m in \u001b[0;36mpolicy_generation\u001b[0;34m(bandit, actions)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mbandit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'LinUCB'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinucb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinUCB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistorystorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mbandit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'LinThompSamp'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/halshater/anaconda/envs/gc_vision/lib/python2.7/site-packages/striatum/bandit/linucb.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, history_storage, model_storage, action_storage, recommendation_cls, context_dimension, alpha)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;34m'theta'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         }\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0maction_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_action_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_action_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MemoryModelStorage' object has no attribute 'iterids'"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
